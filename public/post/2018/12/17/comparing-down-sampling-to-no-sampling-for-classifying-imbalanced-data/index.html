<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Comparing down-sampling to no sampling for classifying imbalanced data | Abnormal Distributions</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/categories/">Articles</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Comparing down-sampling to no sampling for classifying imbalanced data</span></h1>
<h2 class="author">Danny Morris</h2>
<h2 class="date">2018/12/17</h2>
</div>

<main>


<div id="TOC">
<ul>
<li><a href="#r-packages">R packages</a></li>
<li><a href="#data">Data</a></li>
<li><a href="#traintest-split">Train/test split</a></li>
<li><a href="#down-sample-training-data">Down-sample training data</a></li>
<li><a href="#training-parameters">Training parameters</a></li>
<li><a href="#training-on-down-sampled-training-data">Training on down-sampled training data</a></li>
<li><a href="#training-on-full-training-data">Training on full training data</a></li>
<li><a href="#comparing-roc-of-models-on-validation-sets">Comparing ROC of models on validation sets</a></li>
<li><a href="#comparing-roc-of-models-on-test-set">Comparing ROC of models on test set</a></li>
<li><a href="#session-info">Session info</a></li>
</ul>
</div>

<p>In this article, we’ll explore the In the context of binary classification, data is said to be imbalanced when one of the classes is vastly under-represented. The popular Kaggle credit card fraud dataset will be used. It contains <span class="math inline">\(\approx\)</span> 285k transactions with less than 1% being fraudulent and more than 99% being legitimate.</p>
<p>The specific goal of this article is demonstrate the process of training, validating, and testing a classifier on imbalanced data using two re-sampling techniques: <strong>down-sampling</strong> and <strong>SMOTE</strong>. Both techniques give the effect of reducing the size of the training data.</p>
<ul>
<li>down-sampling can significantly reduce training time</li>
<li>performance is typically uncompromised</li>
</ul>
<div id="r-packages" class="section level2">
<h2>R packages</h2>
<pre class="r"><code>library(tidyverse) # data manipulation and %&gt;% operator
library(DBI)       # SQL Server interaction
library(caret)     # machine learning
library(rsample)   # train/test split
library(pROC)      # ROC score</code></pre>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<pre class="r"><code># connect to SQL Server database
local_db &lt;- rsqltools::sql_server_connect(
  server = &quot;DESKTOP-07BKETP&quot;,
  database = &quot;abn_distro&quot;
)</code></pre>
<pre class="r"><code># read from SQL Server and do light preprocessing
sales_tbl &lt;- DBI::dbReadTable(
  conn = local_db,
  name = &quot;SALES_ENGINEERED&quot;
) %&gt;%
  as_tibble() %&gt;%
  filter(CLASS %in% c(&quot;ok&quot;, &quot;fraud&quot;)) %&gt;%
  mutate(CLASS = factor(CLASS, levels = c(&quot;ok&quot;, &quot;fraud&quot;)))</code></pre>
<pre class="r"><code># disconnect database connection
DBI::dbDisconnect(local_db)</code></pre>
<pre class="r"><code>table(sales_tbl$CLASS)</code></pre>
<pre><code>## 
##    ok fraud 
## 14347  1199</code></pre>
</div>
<div id="traintest-split" class="section level2">
<h2>Train/test split</h2>
<p>When I was first learning about machine learning, it took me some time to fully understand how to properly train and test my models. For instance, I used to think that the entire training data was meant for model fitting and the testing data was used for assessing performance. When I would experiment with different models, I would use the same two partitions in the same manner.</p>
<p>Later on, I learned that the training data should actually serve two purposes: model fitting <em>and</em> validation. <strong>Model fitting</strong> is the process of applying an algorithm to a dataset and generating a mathematical representation relating the inputs (features) to the outputs (e.g labels). Think linear regression, an algorithm that takes features (X) and a numeric output (Y) and defines the relationship as <span class="math inline">\(Y = X_0 + X_1*b_1 + ...X_n*b_n\)</span>. <strong>Validation</strong> is the process of assessing the fit of the model and fine tuning the model specifications. If you are comparing a few different models, or experimenting with tweaks to an existing model, you should use the validation data to assess differences in performance. In other words, use the validation data to build a model you think is “best”. Once you’ve developed a quality model, it is then common to retrain the model on the entire training data and assess performance on the <strong>testing</strong> data. Performance on the test data is what should be published or reported to others when describing the performance of your model.</p>
<blockquote>
<p>The validation part of the data should be used for parameter tuning or model selection. Model selection refers to the process of deciding which classification algorithm is best suited to a particular data set. The testing data should not even be looked at during this phase. After tuning the parameters, the classification model is sometimes reconstructed on the entire training data (including the validation but not the test portion). Only at this point, the testing data can be used for evaluating the classification algorithm at the very end.</p>
</blockquote>
<p>In this example, we’ll use 80% of our data for training and 20% for testing. For validation, we’ll use a popular technique called cross-validation to assess the fit of the model and compare results for our two subsampling strategies.</p>
<pre class="r"><code>set.seed(9560)

train_test_split &lt;- rsample::initial_split(
  data = sales_tbl, 
  prop = 0.8,
  strata = &quot;CLASS&quot;
)

imbal_train &lt;- rsample::training(train_test_split)
imbal_test &lt;- rsample::testing(train_test_split)</code></pre>
</div>
<div id="down-sample-training-data" class="section level2">
<h2>Down-sample training data</h2>
<pre class="r"><code>set.seed(9560)

down_train &lt;- caret::downSample(
  x = imbal_train %&gt;% select(-CLASS),
  y = imbal_train$CLASS
)

table(down_train$Class)</code></pre>
<pre><code>## 
##    ok fraud 
##   959   959</code></pre>
</div>
<div id="training-parameters" class="section level2">
<h2>Training parameters</h2>
<p>We’ll be using 5-fold cross-validation repeated 5 times for tuning our models and comparing candidate models.</p>
<pre class="r"><code>train_control &lt;- caret::trainControl(
  method = &quot;repeatedcv&quot;,
  number = 5,
  repeats = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary
)</code></pre>
</div>
<div id="training-on-down-sampled-training-data" class="section level2">
<h2>Training on down-sampled training data</h2>
<pre class="r"><code>set.seed(5627)

downsample_model &lt;- caret::train(
  form = Class ~ ., 
  data = down_train, 
  method = &quot;glm&quot;,
  metric = &quot;AUC&quot;,
  trControl = train_control
)</code></pre>
</div>
<div id="training-on-full-training-data" class="section level2">
<h2>Training on full training data</h2>
<pre class="r"><code>set.seed(5627)

full_model &lt;- caret::train(
  form = CLASS ~ ., 
  data = imbal_train, 
  method = &quot;glm&quot;,
  metric = &quot;ROC&quot;,
  trControl = train_control
)</code></pre>
</div>
<div id="comparing-roc-of-models-on-validation-sets" class="section level2">
<h2>Comparing ROC of models on validation sets</h2>
<pre class="r"><code>models &lt;- list(
  downsample_model = downsample_model,
  full_model = full_model
)

resampling_results &lt;- caret::resamples(models)

summary(resampling_results, metric = &quot;ROC&quot;)$statistics$ROC</code></pre>
<pre><code>##                       Min.   1st Qu.    Median      Mean   3rd Qu.
## downsample_model 0.9346235 0.9540202 0.9578179 0.9570071 0.9617513
## full_model       0.9298210 0.9498380 0.9534291 0.9531504 0.9573488
##                       Max. NA&#39;s
## downsample_model 0.9713270    0
## full_model       0.9710502    0</code></pre>
</div>
<div id="comparing-roc-of-models-on-test-set" class="section level2">
<h2>Comparing ROC of models on test set</h2>
<pre class="r"><code>test_roc &lt;- function(model, data) {
  roc_obj &lt;- roc(data$CLASS, 
                 predict(model, data, type = &quot;prob&quot;)[, &quot;fraud&quot;],
                 levels = c(&quot;ok&quot;, &quot;fraud&quot;))
  ci(roc_obj)
}

probs &lt;- predict(downsample_model, newdata = imbal_test, type = &quot;raw&quot;)</code></pre>
<pre class="r"><code>lapply(
  models, 
  test_roc, 
  data = imbal_test
) %&gt;%
  do.call(&quot;rbind&quot;, .) %&gt;%
  as.data.frame() %&gt;%
  setNames(object = ., nm = c(&quot;lowerCI&quot;, &quot;ROC&quot;, &quot;upperCI&quot;)) </code></pre>
<pre><code>##                    lowerCI       ROC   upperCI
## downsample_model 0.9224116 0.9427573 0.9631031
## full_model       0.9148273 0.9381971 0.9615669</code></pre>
</div>
<div id="session-info" class="section level2">
<h2>Session info</h2>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 3.5.1 (2018-07-02)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 17134)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] bindrcpp_0.2.2       pROC_1.12.1          rsample_0.0.2       
##  [4] broom_0.5.0          caret_6.0-80         lattice_0.20-35     
##  [7] DBI_1.0.0            forcats_0.3.0        stringr_1.3.1       
## [10] dplyr_0.7.6          purrr_0.2.5          readr_1.1.1         
## [13] tidyr_0.8.1          tibble_1.4.2         ggplot2_3.0.0       
## [16] tidyverse_1.2.1      RevoUtils_11.0.1     RevoUtilsMath_11.0.0
## 
## loaded via a namespace (and not attached):
##  [1] nlme_3.1-137         bit64_0.9-7          lubridate_1.7.4     
##  [4] dimRed_0.1.0         httr_1.3.1           rprojroot_1.3-2     
##  [7] tools_3.5.1          backports_1.1.2      R6_2.3.0            
## [10] rpart_4.1-13         lazyeval_0.2.1       colorspace_1.3-2    
## [13] nnet_7.3-12          withr_2.1.2          tidyselect_0.2.4    
## [16] bit_1.1-14           compiler_3.5.1       cli_1.0.1           
## [19] rvest_0.3.2          xml2_1.2.0           bookdown_0.7        
## [22] scales_0.5.0         sfsmisc_1.1-2        DEoptimR_1.0-8      
## [25] robustbase_0.93-3    odbc_1.1.6           digest_0.6.15       
## [28] rmarkdown_1.10       pkgconfig_2.0.2      htmltools_0.3.6     
## [31] rlang_0.3.1          readxl_1.1.0         ddalpha_1.3.4       
## [34] rstudioapi_0.8       bindr_0.1.1          jsonlite_1.5        
## [37] ModelMetrics_1.2.0   magrittr_1.5         Matrix_1.2-14       
## [40] Rcpp_0.12.18         munsell_0.5.0        abind_1.4-5         
## [43] rsqltools_0.0.0.9000 stringi_1.1.7        yaml_2.2.0          
## [46] MASS_7.3-50          plyr_1.8.4           recipes_0.1.3       
## [49] blob_1.1.1           grid_3.5.1           pls_2.7-0           
## [52] crayon_1.3.4         haven_1.1.2          splines_3.5.1       
## [55] hms_0.4.2            knitr_1.20           pillar_1.3.0        
## [58] reshape2_1.4.3       codetools_0.2-15     stats4_3.5.1        
## [61] CVST_0.2-2           magic_1.5-9          glue_1.3.0          
## [64] evaluate_0.12        blogdown_0.9.8       data.table_1.11.8   
## [67] modelr_0.1.2         foreach_1.5.0        cellranger_1.1.0    
## [70] gtable_0.2.0         kernlab_0.9-27       assertthat_0.2.0    
## [73] DRR_0.0.3            xfun_0.3             gower_0.1.2         
## [76] prodlim_2018.04.18   class_7.3-14         survival_2.42-3     
## [79] geometry_0.3-6       timeDate_3043.102    RcppRoll_0.3.0      
## [82] iterators_1.0.10     lava_1.6.3           ipred_0.9-7</code></pre>
</div>

</main>

  <footer>
  <script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script>

  
  <hr/>
  <a href="https://github.com/dannymorris">Github</a> | <a href="https://www.linkedin.com/in/drmorris87/">LinkedIn</a> | <a href="mailto:drmorris87@outlook.com">Email</a>
  
  </footer>
  </body>
</html>

