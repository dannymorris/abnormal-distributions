<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>A specific comparison of feature engineering in R and Python | Abnormal Distributions</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/about/">About</a></li>
      
      <li><a href="/post/">All Posts</a></li>
      
      <li><a href="/categories/">By Topic</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">A specific comparison of feature engineering in R and Python</span></h1>
<h2 class="author">Danny Morris</h2>
<h2 class="date">2018/01/09</h2>
</div>

<main>


<div id="TOC">
<ul>
<li><a href="#purpose">Purpose</a></li>
<li><a href="#original-data">Original data</a></li>
<li><a href="#features-to-engineer">Features to engineer</a></li>
<li><a href="#r">R</a></li>
<li><a href="#python">Python</a></li>
</ul>
</div>

<div id="purpose" class="section level2">
<h2>Purpose</h2>
<p>Moving from raw data to data that is prime for analysis is called feature engineering and it is a fundamental aspect of data science. Experienced data scientists will agree that feature engineering is an essential skill.</p>
<p>This article demonstrates the same engineering pipeline written in R and Python. The pipeline is not particularly complicated, though it resembles something that a data scientist would do. I’ll be using a dataset of sales transactions that need to be engineered in order to classify fraudulent and legitimate sales.</p>
</div>
<div id="original-data" class="section level2">
<h2>Original data</h2>
<pre class="r"><code>library(DMwR) # install.packages(&quot;DMwR&quot;)

data(sales, package = &quot;DMwR&quot;)

head(sales)</code></pre>
<pre><code>##   ID Prod Quant   Val Insp
## 1 v1   p1   182  1665 unkn
## 2 v2   p1  3072  8780 unkn
## 3 v3   p1 20393 76990 unkn
## 4 v4   p1   112  1100 unkn
## 5 v3   p1  6164 20260 unkn
## 6 v5   p2   104  1155 unkn</code></pre>
<p>The raw data contains five variables:</p>
<p>ID: salesperson identifier</p>
<p>Prod: product identifier</p>
<p>Quant: quantity of items sold in sale</p>
<p>Val: total price of the sale</p>
<p>Insp: whether the sale is known to be fraudulent or not</p>
<p>Our end goal is to build a classifier to predict fraudulent sales. We won’t actually do that in this article, but the features we engineer will be related to this goal.</p>
</div>
<div id="features-to-engineer" class="section level2">
<h2>Features to engineer</h2>
<p>Let’s assume that fraudulent transactions can take many forms. For example, perhaps transactions for an extremely high price are an indication of credit card theft. Alternatively, transactions with many items sold for an extremely low price are an indication of suspicous discounts.</p>
<p>In our attempt to capture fraudulent sales and the various forms it can take, let’s engineer the following five features:</p>
<ol style="list-style-type: decimal">
<li><p>Price per quantity, log transformed (LPPQ): This is the total price divided by the toal quantity with a base 10 log transformation.</p></li>
<li><p>Squared difference between LPPQ and global mean LPPQ</p></li>
<li><p>Squared difference between LPPQ and mean LPPQ grouped by salesperson</p></li>
<li><p>Squared difference between LPPQ and mean LPPQ grouped by product</p></li>
<li><p>Squared difference between LPPQ and mean LPPQ grouped by salesperson and product</p></li>
</ol>
<p>In addition to these engineered features, we’ll perform some additonal preprocessing steps:</p>
<ul>
<li>remove rows with any missing values</li>
<li>randomly sample 500 fraudulent and 500 legitimate sales</li>
</ul>
</div>
<div id="r" class="section level2">
<h2>R</h2>
<p>The tidyverse ecosystem in R contains some outstanding packages for data manipulation. Most notably, the dplyr package is excellent for transformations and the tidyr package is excellent for reshaping. Both are included in the tidyverse and do not need to be installed or loaded separately. Our entire pipeline is completed using these two packages (actually, we also use the readr package for importing the csv).</p>
<p>The tidyverse utilizes the <code>%&gt;%</code> symbol (known as the “pipe” symbol) for chaining together steps in an analysis pipeline. Here is the full feature engineering pipeline in R.</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre class="r"><code>sales &lt;- sales %&gt;%
  drop_na() %&gt;%
  filter(Insp %in% c(&quot;fraud&quot;, &quot;ok&quot;)) %&gt;%  
  group_by(Insp) %&gt;%
  sample_n(size = 500) %&gt;%
  ungroup()

sq_diff &lt;- function(x, y) (x - y)^2

r_engineered &lt;- sales %&gt;%
  mutate(LPPQ = log10(Val / Quant)) %&gt;%
  mutate(LPPQ_2 = sq_diff(LPPQ, mean(LPPQ))) %&gt;%
  group_by(ID) %&gt;%
  mutate(LPPQ_3 = sq_diff(LPPQ, mean(LPPQ))) %&gt;%
  group_by(Prod) %&gt;%
  mutate(LPPQ_4 = sq_diff(LPPQ, mean(LPPQ))) %&gt;%
  group_by(ID, Prod) %&gt;%
  mutate(LPPQ_5 = sq_diff(LPPQ, mean(LPPQ))) %&gt;%
  ungroup()

head(r_engineered)</code></pre>
<pre><code>## # A tibble: 6 x 10
##   ID    Prod  Quant   Val Insp   LPPQ  LPPQ_2 LPPQ_3     LPPQ_4 LPPQ_5
##   &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;
## 1 v1368 p1215   102  1170 ok    1.06  0.00746  0     0.00280         0
## 2 v251  p920  16100 27255 ok    0.229 0.554    0     0               0
## 3 v701  p3649   527 56525 ok    2.03  1.12     0.263 0.926           0
## 4 v22   p1125   202  2220 ok    1.04  0.00460  0     0.00945         0
## 5 v1109 p1910   173  2090 ok    1.08  0.0119   0     0.0331          0
## 6 v252  p994    113  1160 ok    1.01  0.00146  0.164 0.00000353      0</code></pre>
</div>
<div id="python" class="section level2">
<h2>Python</h2>
<p>We’ll use a combination of pandas, numpy, and scikit learn to engineer the features in Python.</p>
<pre class="r"><code>reticulate::use_condaenv(&quot;r-reticulate&quot;, required = TRUE)</code></pre>
<pre class="python"><code>import pandas as pd
import numpy as np
from sklearn.utils import resample </code></pre>
<pre class="python"><code>sales = pd.read_csv(&#39;sales.csv&#39;)

sales = sales.dropna()

sales_ok = sales[sales.Insp == &#39;ok&#39;]
sales_fraud = sales[sales.Insp == &#39;fraud&#39;]

resample_ok = resample(sales_ok, replace = False, n_samples = 500)
resample_fraud = resample(sales_fraud, replace = False, n_samples = 500) 

sales = pd.concat([resample_ok, resample_fraud])

sales[&#39;LPPQ&#39;] = np.log10(sales.Val/sales.Quant)
sales[&#39;LPPQ_2&#39;] = sales.LPPQ - np.mean(sales.LPPQ)

def get_group_mean(group_vars, col_name):
  group_df = sales.groupby(group_vars, as_index = False)[&#39;LPPQ&#39;]
  group_mean = group_df.mean()
  group_mean = group_mean.rename(index = str, columns = {&quot;LPPQ&quot;: col_name})
  return group_mean

LPPQ_3 = get_group_mean(group_vars = [&#39;ID&#39;], col_name = &#39;LPPQ_3&#39;)
LPPQ_4 = get_group_mean(group_vars = [&#39;Prod&#39;], col_name = &#39;LPPQ_4&#39;)
LPPQ_5 = get_group_mean(group_vars = [&#39;Prod&#39;, &#39;ID&#39;], col_name = &#39;LPPQ_5&#39;)

sales = sales.merge(LPPQ_3, how = &#39;inner&#39;, on = &#39;ID&#39;)
sales = sales.merge(LPPQ_4, how = &#39;inner&#39;, on = &#39;Prod&#39;) 
sales = sales.merge(LPPQ_5, how = &#39;inner&#39;, on = [&#39;ID&#39;, &#39;Prod&#39;])

def sq_diff(x):
  return (x - sales.LPPQ)**2
  
sales[[&#39;LPPQ_2&#39;,&#39;LPPQ_3&#39;, &#39;LPPQ_4&#39;, &#39;LPPQ_5&#39;]] = sales[[&#39;LPPQ_2&#39;,&#39;LPPQ_3&#39;, &#39;LPPQ_4&#39;, &#39;LPPQ_5&#39;]].apply(sq_diff)

sales.head()</code></pre>
<pre><code>##       ID   Prod    Quant       Val  ...    LPPQ_2    LPPQ_3    LPPQ_4  LPPQ_5
## 0  v1146  p1398    126.0    1020.0  ...  0.904722  0.006759  0.054679     0.0
## 1   v672  p1398    111.0    1085.0  ...  0.904722  0.041993  0.023091     0.0
## 2  v5717  p1398  16985.0  155805.0  ...  0.904722  0.000000  0.032238     0.0
## 3  v1152  p1398    155.0    1075.0  ...  0.904722  0.000000  0.090593     0.0
## 4  v4667  p1398  40860.0  137010.0  ...  0.904722  0.000000  0.380208     0.0
## 
## [5 rows x 10 columns]</code></pre>
</div>

</main>

  <footer>
  <script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143402170-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-143402170-1');
</script>


  
  <hr/>
  <a href="https://github.com/dannymorris">Github</a> | <a href="https://www.linkedin.com/in/drmorris87/">LinkedIn</a> | <a href="mailto:drmorris87@outlook.com">Email</a>
  
  </footer>
  </body>
</html>

