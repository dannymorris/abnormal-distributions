<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Abnormal Distributions</title>
    <link>/post/</link>
    <description>Recent content in Posts on Abnormal Distributions</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Example Gradient Boosted Classifier Using Scikit Learn</title>
      <link>/post/2019/06/25/example-gradient-boosted-classifier-using-scikit-learn/</link>
      <pubDate>Tue, 25 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/06/25/example-gradient-boosted-classifier-using-scikit-learn/</guid>
      <description>a.sourceLine { display: inline-block; line-height: 1.25; }a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }a.sourceLine:empty { height: 1.2em; }.sourceCode { overflow: visible; }code.sourceCode { white-space: pre; position: relative; }div.sourceCode { margin: 1em 0; }pre.sourceCode { margin: 0; }@media screen {div.sourceCode { overflow: auto; }}@media print {code.sourceCode { white-space: pre-wrap; }a.sourceLine { text-indent: -1em; padding-left: 1em; }}pre.</description>
    </item>
    
    <item>
      <title>MLS Local Execution</title>
      <link>/post/2019/06/23/mls-local-execution/</link>
      <pubDate>Sun, 23 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/06/23/mls-local-execution/</guid>
      <description>sessionInfo()## R version 3.5.2 (2018-12-20)## Platform: x86_64-w64-mingw32/x64 (64-bit)## Running under: Windows 10 x64 (build 18362)## ## Matrix products: default## ## locale:## [1] LC_COLLATE=English_United States.1252 ## [2] LC_CTYPE=English_United States.1252 ## [3] LC_MONETARY=English_United States.1252## [4] LC_NUMERIC=C ## [5] LC_TIME=English_United States.1252 ## ## attached base packages:## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached):## [1] compiler_3.</description>
    </item>
    
    <item>
      <title>Test</title>
      <link>/post/2019/06/16/test/</link>
      <pubDate>Sun, 16 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/06/16/test/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Basic Plots using Plotly in R</title>
      <link>/post/2019/06/15/basic-plotly/</link>
      <pubDate>Sat, 15 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/06/15/basic-plotly/</guid>
      <description>PackagesPackageslibrary(tidyverse)## -- Attaching packages ------------------- tidyverse 1.2.1 --## v ggplot2 3.1.0 v purrr 0.3.1 ## v tibble 2.1.1 v dplyr 0.8.0.1## v tidyr 0.8.3 v stringr 1.4.0 ## v readr 1.3.1 v forcats 0.4.0## Warning: package &amp;#39;tibble&amp;#39; was built under R version 3.5.3## -- Conflicts ---------------------- tidyverse_conflicts() --## x dplyr::filter() masks stats::filter()## x dplyr::lag() masks stats::lag()library(gapminder)## Warning: package &amp;#39;gapminder&amp;#39; was built under R version 3.</description>
    </item>
    
    <item>
      <title>Tidy Binomial Calculator Using the probs Package</title>
      <link>/post/2019/04/08/tidy-binomial-calculator/</link>
      <pubDate>Mon, 08 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/04/08/tidy-binomial-calculator/</guid>
      <description>InstallSimulated DataThis short post introduces a simple R package called probs that I created for tidy binomial probability calculations. In the future, probs will include similar functions for calculating probability assuming different probability distributions.
InstallThe probs package lives on GitHub.
library(devtools)devtools::install_github(&amp;quot;dannymorris/probs&amp;quot;)Simulated DataRecently, I needed to communicate to a larger audience the probability of detecting a particular event. Specifically, a pre-existing process was in place that required humans to sift through a sample of 100 PDF documents out of 40,000 documents.</description>
    </item>
    
    <item>
      <title>Detecting, Extracting, and Comparing Address Labels</title>
      <link>/post/2019/03/20/detecting-extracting-and-comparing-address-labels/</link>
      <pubDate>Wed, 20 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/03/20/detecting-extracting-and-comparing-address-labels/</guid>
      <description>ApplicationsObject DetectionOptical Character RecognitionString MatchingChallengesR PackagesBusinesses send and receive mail from customers regularly. Mailing address labels are vital to the success of mailings. Incomplete or inaccurate labels stemming from poor data source quality can negatively impact customer relationships, brand perception, and internal performance metrics. Good quality data is key, though it is sometimes difficult to achieve.
This document describes some methodologies for processing and analyzing address labels using techniques from computer science and artificial intelligence that scale to large data sets.</description>
    </item>
    
    <item>
      <title>Bag of Words Text Classification in R</title>
      <link>/post/2019/02/17/text-classification-using-text2vec/</link>
      <pubDate>Sun, 17 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/17/text-classification-using-text2vec/</guid>
      <description>a.sourceLine { display: inline-block; line-height: 1.25; }a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }a.sourceLine:empty { height: 1.2em; }.sourceCode { overflow: visible; }code.sourceCode { white-space: pre; position: relative; }div.sourceCode { margin: 1em 0; }pre.sourceCode { margin: 0; }@media screen {div.sourceCode { overflow: auto; }}@media print {code.sourceCode { white-space: pre-wrap; }a.sourceLine { text-indent: -1em; padding-left: 1em; }}pre.</description>
    </item>
    
    <item>
      <title>Tidy Text Mining in R</title>
      <link>/post/2019/02/10/tidy-text-mining-in-r/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/02/10/tidy-text-mining-in-r/</guid>
      <description>a.sourceLine { display: inline-block; line-height: 1.25; }a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }a.sourceLine:empty { height: 1.2em; }.sourceCode { overflow: visible; }code.sourceCode { white-space: pre; position: relative; }div.sourceCode { margin: 1em 0; }pre.sourceCode { margin: 0; }@media screen {div.sourceCode { overflow: auto; }}@media print {code.sourceCode { white-space: pre-wrap; }a.sourceLine { text-indent: -1em; padding-left: 1em; }}pre.</description>
    </item>
    
    <item>
      <title>Basics of deploying Flask applications to localhost on Windows</title>
      <link>/post/2019/01/20/using-flask-to-deploy-predictive-models/</link>
      <pubDate>Sun, 20 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019/01/20/using-flask-to-deploy-predictive-models/</guid>
      <description>PurposeEnvironmentCreate and activate conda environment in Anaconda PromptInstall dependenciesVery simple Flask appRun the appTest the appNext stepsPurposeDeploying production code is one of the toughest challenges that data scientists face. There seems to be significantly more content available on model development than model deployment. In this article, I document my experience building and deploying an web application written in Python using the Flask microframework.</description>
    </item>
    
    <item>
      <title>Comparing down-sampling to no sampling for classifying imbalanced data</title>
      <link>/post/2018/12/17/comparing-down-sampling-to-no-sampling-for-classifying-imbalanced-data/</link>
      <pubDate>Mon, 17 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/12/17/comparing-down-sampling-to-no-sampling-for-classifying-imbalanced-data/</guid>
      <description>R packagesDataTrain/test splitDown-sample training dataTraining parametersTraining on down-sampled training dataTraining on full training dataComparing ROC of models on validation setsComparing ROC of models on test setSession infoIn this article, we’ll explore the In the context of binary classification, data is said to be imbalanced when one of the classes is vastly under-represented. The popular Kaggle credit card fraud dataset will be used.</description>
    </item>
    
    <item>
      <title>A specific comparison of feature engineering in R and Python</title>
      <link>/post/2018/01/09/a-specific-comparison-of-feature-engineering-in-r-and-python/</link>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/09/a-specific-comparison-of-feature-engineering-in-r-and-python/</guid>
      <description>PurposeOriginal dataFeatures to engineerRPythonPurposeMoving from raw data to data that is prime for analysis is called feature engineering and it is a fundamental aspect of data science. Experienced data scientists will agree that feature engineering is an essential skill.
This article demonstrates the same engineering pipeline written in R and Python. The pipeline is not particularly complicated, though it resembles something that a data scientist would do.</description>
    </item>
    
    <item>
      <title>Getting started with Python in R Markdown using the reticulate package</title>
      <link>/post/2018/01/09/getting-started-with-python-in-r-markdown-using-the-reticulate-package/</link>
      <pubDate>Tue, 09 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/09/getting-started-with-python-in-r-markdown-using-the-reticulate-package/</guid>
      <description>AboutInstall and load reticulateUsing conda environmentsInstalling Python librariesWriting Python code in R MarkdownAboutOne of my current goals is to gain basic familiarity with Python as a data science language. I’ve spent some time recently working with Pandas, seaborn, and sci-kit learn. I’ve had a pleasant experience working in the Spyder IDE. Still, nothing beats R Markdown for creating highly polished, reproducible documents and analyses.</description>
    </item>
    
  </channel>
</rss>