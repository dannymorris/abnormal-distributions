<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Text classification using sparse matrices, bag of words, TF-IDF, and penalized logistic regression | Abnormal Distributions</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    
  </head>

  <body>
    <nav>
    <ul class="menu">
      
      <li><a href="/">Home</a></li>
      
      <li><a href="/post/">All Posts</a></li>
      
      <li><a href="/categories/">By Topic</a></li>
      
    </ul>
    <hr/>
    </nav>

<div class="article-meta">
<h1><span class="title">Text classification using sparse matrices, bag of words, TF-IDF, and penalized logistic regression</span></h1>
<h2 class="author">Danny Morris</h2>
<h2 class="date">2019/02/17</h2>
</div>

<main>

<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<div id="TOC">
<ul>
<li><a href="#packages">Packages</a></li>
<li><a href="#data">Data</a></li>
<li><a href="#model-function">Model function</a></li>
<li><a href="#implement-cross-validation">Implement cross validation</a></li>
<li><a href="#evaluate-cv-results">Evaluate CV results</a></li>
</ul>
</div>

<p>This post demonstrates a strategy for text classification (binary) using efficient data representation, transformation, and modeling techniques. Using the <code>text2vec</code> package, raw text is tokenized, converted to sparse bag-of-words feature matrix, and weighted using TF-IDF. The weighted bag-of-words feature matrix is used as an input to an efficient penalized logistic regression algorithm implemented in the <code>glmnet</code> pacakge. This pipeline is implemented along with repeated cross validation for robust model evaluation.</p>
<div id="packages" class="section level2">
<h2>Packages</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(text2vec)     <span class="co"># NLP tools</span>
<span class="kw">library</span>(tidytext)     <span class="co"># tidy text mining</span>
<span class="kw">library</span>(glmnet)       <span class="co"># logistic regression</span>
<span class="kw">library</span>(tidymodels)   <span class="co"># modeling</span>
<span class="kw">library</span>(tidyverse)    <span class="co"># general purpose data manipulation</span>
<span class="kw">library</span>(textstem)     <span class="co"># word lemmatization</span></code></pre>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<pre class="sourceCode r"><code class="sourceCode r">text_df &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;text_clf.csv&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sample_frac</span>(<span class="fl">0.1</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">doc_id =</span> <span class="kw">row_number</span>())</code></pre>
</div>
<div id="model-function" class="section level2">
<h2>Model function</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Arguments: training and testing data</span>
<span class="co"># Returns: AUC of out-of-sample (testing) predictions</span>
model_function &lt;-<span class="st"> </span><span class="cf">function</span>(train, test) {
  
  model_dfs &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">train =</span> train, <span class="dt">test =</span> test)
  
  <span class="co">############</span>
  <span class="co"># Tokenize #</span>
  <span class="co">############</span>
  
  tokens &lt;-<span class="st"> </span>model_dfs <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">map</span>(., <span class="cf">function</span>(x) {
      x <span class="op">%&gt;%</span>
<span class="st">        </span>tidytext<span class="op">::</span><span class="kw">unnest_tokens</span>(word, Text) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">        </span><span class="co"># remove stopwords</span>
<span class="st">        </span><span class="kw">anti_join</span>(stop_words, <span class="dt">by =</span> <span class="st">&quot;word&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="co"># lemmatize</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">word =</span> textstem<span class="op">::</span><span class="kw">lemmatize_words</span>(word)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">str_replace_all</span>(word, <span class="st">&quot;[^[:alpha:]]&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">        </span><span class="kw">mutate</span>(<span class="dt">word =</span> <span class="kw">str_replace</span>(<span class="kw">gsub</span>(<span class="st">&quot;</span><span class="ch">\\</span><span class="st">s+&quot;</span>, <span class="st">&quot; &quot;</span>, <span class="kw">str_trim</span>(word)), <span class="st">&quot;B&quot;</span>, <span class="st">&quot;b&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="co"># obtain the vector of words (tokens) for each training and testing document</span>
<span class="st">        </span><span class="kw">split</span>(.<span class="op">$</span>doc_id) <span class="op">%&gt;%</span>
<span class="st">        </span><span class="kw">map</span>(., <span class="cf">function</span>(x) x <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">pull</span>(word))
    })
  
  <span class="co">########################################</span>
  <span class="co"># Create vocabulary from training data #</span>
  <span class="co">########################################</span>
  
  iter_train &lt;-<span class="st"> </span>text2vec<span class="op">::</span><span class="kw">itoken</span>(<span class="dt">iterable =</span> tokens<span class="op">$</span>train, 
                                 <span class="dt">ids =</span> model_dfs<span class="op">$</span>train<span class="op">$</span>doc_id,
                                 <span class="dt">progressbar =</span> <span class="ot">FALSE</span>)
  
  iter_test &lt;-<span class="st"> </span>text2vec<span class="op">::</span><span class="kw">itoken</span>(<span class="dt">iterable =</span> tokens<span class="op">$</span>test, 
                                <span class="dt">ids =</span> model_dfs<span class="op">$</span>test<span class="op">$</span>doc_id,
                                <span class="dt">progressbar =</span> <span class="ot">FALSE</span>)
  
  vocab &lt;-<span class="st"> </span>text2vec<span class="op">::</span><span class="kw">create_vocabulary</span>(iter_train)
  
  vectorizer &lt;-<span class="st"> </span>text2vec<span class="op">::</span><span class="kw">vocab_vectorizer</span>(vocab)
  
  <span class="co">##########################</span>
  <span class="co"># Document-term matrices #</span>
  <span class="co">##########################</span>
  
  doc_term_train =<span class="st"> </span>text2vec<span class="op">::</span><span class="kw">create_dtm</span>(iter_train, vectorizer)
  doc_term_test =<span class="st"> </span><span class="kw">create_dtm</span>(iter_test, vectorizer)
  
  <span class="co">##########</span>
  <span class="co"># TF-IDF #</span>
  <span class="co">##########</span>
  
  tf_idf =<span class="st"> </span>TfIdf<span class="op">$</span><span class="kw">new</span>()
  
  <span class="co"># fit tf-idf to training data</span>
  doc_term_train_tfidf =<span class="st"> </span><span class="kw">fit_transform</span>(doc_term_train, tf_idf)
  
  <span class="co"># apply pre-trained tf-idf transformation to testing data</span>
  doc_term_test_tfidf  =<span class="st"> </span><span class="kw">transform</span>(doc_term_test, tf_idf)
  
  <span class="co">####################</span>
  <span class="co"># Train classifier #</span>
  <span class="co">####################</span>
  
  glmnet_classifier =<span class="st"> </span><span class="kw">cv.glmnet</span>(
    <span class="dt">x =</span> doc_term_train_tfidf, 
    <span class="dt">y =</span> model_dfs<span class="op">$</span>train<span class="op">$</span>Label,
    <span class="dt">family =</span> <span class="st">&#39;binomial&#39;</span>, 
    <span class="dt">alpha =</span> <span class="dv">1</span>,
    <span class="dt">type.measure =</span> <span class="st">&quot;auc&quot;</span>,
    <span class="dt">nfolds =</span> <span class="dv">5</span>,
    <span class="dt">thresh =</span> <span class="fl">1e-3</span>,
    <span class="dt">maxit =</span> <span class="fl">1e3</span>)
  
  probs =<span class="st"> </span><span class="kw">predict</span>(glmnet_classifier, doc_term_test_tfidf, <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>)[, <span class="dv">1</span>]
  
  <span class="co">###########################</span>
  <span class="co"># Measure AUC on test set #</span>
  <span class="co">###########################</span>
  
  test_auc =<span class="st"> </span>glmnet<span class="op">:::</span><span class="kw">auc</span>(
    <span class="dt">y =</span> model_dfs<span class="op">$</span>test<span class="op">$</span>Label <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.integer</span>(),
    <span class="dt">prob =</span> probs
  )
  
  <span class="kw">return</span>(test_auc)
  
}</code></pre>
</div>
<div id="implement-cross-validation" class="section level2">
<h2>Implement cross validation</h2>
<p>Using <code>purrr::map()</code>, run the model function within each cross validation fold.</p>
<pre class="sourceCode r"><code class="sourceCode r">n_folds &lt;-<span class="st"> </span><span class="dv">5</span>
n_repeats &lt;-<span class="st"> </span><span class="dv">3</span>

cv_splits &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">vfold_cv</span>(text_df, 
                               <span class="dt">v =</span> n_folds, 
                               <span class="dt">repeats =</span> n_repeats, 
                               <span class="dt">strata =</span> <span class="st">&#39;Label&#39;</span>)

cv_models &lt;-<span class="st"> </span><span class="kw">map_dbl</span>(cv_splits<span class="op">$</span>splits, <span class="cf">function</span>(cv) {
  train &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">training</span>(cv)
  test &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">testing</span>(cv)
  <span class="kw">model_function</span>(<span class="dt">train =</span> train, <span class="dt">test =</span> test)
})</code></pre>
</div>
<div id="evaluate-cv-results" class="section level2">
<h2>Evaluate CV results</h2>
<p>Evaluate performance of the classifier by looking at the distribution of AUC across all cross validation folds.</p>
<pre class="sourceCode r"><code class="sourceCode r">cv_models <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">enframe</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Distribution of AUC across all cross validation folds&quot;</span>,
       <span class="dt">subtitle =</span> <span class="kw">paste</span>(<span class="st">&quot;N models = &quot;</span>, <span class="kw">length</span>(cv_splits<span class="op">$</span>splits)),
       <span class="dt">x =</span> <span class="st">&quot;AUC&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_x_continuous</span>(<span class="dt">breaks =</span> scales<span class="op">::</span><span class="kw">pretty_breaks</span>(<span class="dt">n=</span><span class="dv">10</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<p><img src="/post/2019-02-17-text-classification-using-text2vec_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>

</main>

  <footer>
  <script src="//yihui.name/js/math-code.js"></script>
<script async src="//mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=UA-143402170-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-143402170-1');
</script>


  
  <hr/>
  <a href="https://github.com/dannymorris">Github</a> | <a href="https://www.linkedin.com/in/drmorris87/">LinkedIn</a> | <a href="mailto:drmorris87@outlook.com">Email</a>
  
  </footer>
  </body>
</html>

