---
title: A strategy for rare class learning using data-centric ensembling
author: Danny Morris
date: 2019-07-01
output: 
  blogdown::html_page:
    toc: true
    highlight: pygments
slug: rare-class-ensemble
categories:
  - R
  - Classification
tags:
  - R
  - Classification
editor_options: 
  chunk_output_type: console
---

<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#packages">Packages</a></li>
<li><a href="#data">Data</a></li>
<li><a href="#training-and-out-of-sample-splits">Training and out-of-sample splits</a></li>
<li><a href="#generate-subsamples-from-training-data">Generate subsamples from training data</a></li>
<li><a href="#fit-ensemble-of-models">Fit ensemble of models</a></li>
<li><a href="#predicted-labels-via-ensemble">Predicted labels via ensemble</a></li>
<li><a href="#results">Results</a></li>
</ul>
</div>

<div id="overview" class="section level2">
<h2>Overview</h2>
<p>This post demonstrates a strategy for predicting out-of-sample cases using a binary classification ensemble when the training data contains imbalanced classes. This strategy is described by <a href="http://charuaggarwal.net/">Charu Aggarwal</a> in section 7.2 of his book <a href="https://www.amazon.com/Outlier-Analysis-Charu-C-Aggarwal/dp/3319475770/ref=pd_cp_14_1?pd_rd_w=8M3qy&amp;pf_rd_p=ef4dc990-a9ca-4945-ae0b-f8d549198ed6&amp;pf_rd_r=3TGSZZ1H5HYKMT0G80Q8&amp;pd_rd_r=f1e3c156-9e78-11e9-801d-cdc96cae2e7b&amp;pd_rd_wg=DXbV0&amp;pd_rd_i=3319475770&amp;psc=1&amp;refRID=3TGSZZ1H5HYKMT0G80Q8">Outlier Analysis</a>.</p>
<p>This ensemble strategy aims to reduce the overall variance of the classification model by fitting several models to different subsamples of the training data, generating predictions for out-of-sample cases using the parameter estimates from each model, then combining the predictions for each out-of-sample case to arrive at a final prediction for each out-of-sample case. It is a useful strategy when the outcome being modeled is rare, e.g.Â unexpected health crisis.</p>
</div>
<div id="packages" class="section level2">
<h2>Packages</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse) 
<span class="kw">library</span>(rsample)   
<span class="kw">library</span>(ranger) 
<span class="kw">library</span>(imbalance)
<span class="kw">library</span>(yardstick)

<span class="kw">options</span>(<span class="dt">yardstick.event_first =</span> F)</code></pre>
</div>
<div id="data" class="section level2">
<h2>Data</h2>
<pre class="sourceCode r"><code class="sourceCode r">sample_df &lt;-<span class="st"> </span>imbalance<span class="op">::</span>banana <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">as_tibble</span>()</code></pre>
<p>Class distribution.</p>
<pre class="sourceCode r"><code class="sourceCode r">sample_df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">count</span>(Class) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pct_n =</span> n<span class="op">/</span><span class="kw">sum</span>(n))</code></pre>
<pre><code>## # A tibble: 2 x 3
##   Class        n pct_n
##   &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;
## 1 negative  2376   0.9
## 2 positive   264   0.1</code></pre>
</div>
<div id="training-and-out-of-sample-splits" class="section level2">
<h2>Training and out-of-sample splits</h2>
<pre class="sourceCode r"><code class="sourceCode r">split_pct &lt;-<span class="st"> </span><span class="fl">0.8</span>

<span class="kw">set.seed</span>(<span class="dv">9560</span>)

split_idx &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">initial_split</span>(
  <span class="dt">data =</span> sample_df, 
  <span class="dt">prop =</span> split_pct,
  <span class="dt">strata =</span> <span class="st">&quot;Class&quot;</span>
)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">train &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">training</span>(split_idx)

out_of_sample &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">assessment</span>(split_idx)</code></pre>
</div>
<div id="generate-subsamples-from-training-data" class="section level2">
<h2>Generate subsamples from training data</h2>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># determine the number of rows to which the negative class is down-sampled</span>
<span class="co"># by default, set to the number of positive cases</span>
downsample_level &lt;-<span class="st"> </span>train <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(Class <span class="op">==</span><span class="st"> &quot;positive&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">nrow</span>()

subsample_idx &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,  <span class="dv">25</span>, <span class="dv">1</span>)

subsamples &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(subsample_idx, <span class="cf">function</span>(idx) {
  train <span class="op">%&gt;%</span>
<span class="st">    </span>dplyr<span class="op">::</span><span class="kw">group_by</span>(Class) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">sample_n</span>(<span class="dt">size =</span> downsample_level) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ungroup</span>()
}) </code></pre>
</div>
<div id="fit-ensemble-of-models" class="section level2">
<h2>Fit ensemble of models</h2>
<pre class="sourceCode r"><code class="sourceCode r">models &lt;-<span class="st"> </span><span class="kw">map</span>(subsamples, <span class="cf">function</span>(idx) {
  ranger_model &lt;-<span class="st"> </span>ranger<span class="op">::</span><span class="kw">ranger</span>(
    <span class="dt">formula =</span> <span class="kw">as.factor</span>(Class) <span class="op">~</span><span class="st"> </span>.,
    <span class="dt">data =</span> idx,
    <span class="dt">probability =</span> T
  )
})</code></pre>
</div>
<div id="predicted-labels-via-ensemble" class="section level2">
<h2>Predicted labels via ensemble</h2>
<pre class="sourceCode r"><code class="sourceCode r">probs &lt;-<span class="st"> </span><span class="kw">map</span>(models, <span class="cf">function</span>(idx) {
  <span class="kw">predict</span>(idx, <span class="dt">data =</span> out_of_sample)<span class="op">$</span>predictions[, <span class="st">&quot;positive&quot;</span>]
}) 

avg_prob &lt;-<span class="st"> </span>probs <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_cols</span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">apply</span>(., <span class="fl">1.</span>, mean)

pred_label &lt;-<span class="st"> </span><span class="kw">ifelse</span>(avg_prob <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&quot;positive&quot;</span>, <span class="st">&quot;negative&quot;</span>)</code></pre>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<pre class="sourceCode r"><code class="sourceCode r">ensemble_f1 &lt;-<span class="st"> </span><span class="kw">f_meas_vec</span>(out_of_sample<span class="op">$</span>Class, <span class="kw">factor</span>(pred_label))

<span class="kw">map_dbl</span>(probs, <span class="cf">function</span>(prob) {
  label &lt;-<span class="st"> </span><span class="kw">ifelse</span>(prob <span class="op">&gt;=</span><span class="st"> </span><span class="fl">0.5</span>, <span class="st">&quot;positive&quot;</span>, <span class="st">&quot;negative&quot;</span>)
  yardstick<span class="op">::</span><span class="kw">f_meas_vec</span>(out_of_sample<span class="op">$</span>Class, <span class="kw">factor</span>(label))
}) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">enframe</span>(<span class="dt">name =</span> <span class="st">&quot;Subsample&quot;</span>, <span class="dt">value =</span> <span class="st">&quot;Subsample_F1&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Ensemble_F1 =</span> ensemble_f1) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(Metric, Value, <span class="op">-</span>Subsample) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Subsample, <span class="dt">y =</span> Value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> Metric, <span class="dt">color =</span> Metric), <span class="dt">lwd =</span> <span class="dv">1</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_color_manual</span>(<span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;gray80&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;F1 across 25 subsamples&quot;</span>,
       <span class="dt">subtitle =</span> <span class="st">&quot;The ensemble reduces variation and improves accuracy.&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<p><img src="/post/2019-07-01-rare-class-ensemble_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
</div>
