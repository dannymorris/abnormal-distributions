---
title: "An Efficient Ensemble Approach for Supervised Classification with Imbalanced Classes"
author: "Danny Morris"
date: "2018-11-20"
categories: ['Machine Learning', 'R', 'Classification']
output: 
  blogdown::html_page:
    toc: true
    highlight: pygments
editor_options: 
  chunk_output_type: console
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>
<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<div id="TOC">
<ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#r-packages">R packages</a></li>
<li><a href="#data">Data</a></li>
<li><a href="#feature-engineering">Feature Engineering</a></li>
<li><a href="#global-traintest-split">Global Train/Test Split</a></li>
<li><a href="#subsampling">Subsampling</a><ul>
<li><a href="#give-specifications-for-the-subsampling-procedure.">Give specifications for the subsampling procedure.</a></li>
<li><a href="#generate-subsamples">Generate subsamples</a></li>
</ul></li>
<li><a href="#training">Training</a><ul>
<li><a href="#fit-individual-model-to-each-subsample">Fit individual model to each subsample</a></li>
</ul></li>
<li><a href="#testing">Testing</a><ul>
<li><a href="#apply-individual-models-to-predict-testing-set">Apply individual models to predict testing set</a></li>
<li><a href="#combine-predictions-via-majority-vote">Combine predictions via majority vote</a></li>
<li><a href="#evaluate-performance">Evaluate performance</a></li>
</ul></li>
</ul>
</div>

<div id="overview" class="section level1">
<h1>Overview</h1>
<p>This article demonstrates an approach for supervised learning using an ensemble of classifiers applied to imbalanced data. At the core of the ensemble technique is <em>data-centric subsampling.</em> The basic steps include:</p>
<ol style="list-style-type: decimal">
<li><p>Designate 80% of the original data for training and 20% for testing. These percentages can be modified as needed.</p></li>
<li><p>Decide on <em>S</em> number of subsamples. Between 10 and 25 is recommended by <a href="http://charuaggarwal.net/">Charu Aggarwal</a> in his book <a href="https://www.amazon.com/Outlier-Analysis-Charu-C-Aggarwal/dp/3319475770/ref=pd_cp_14_1?pd_rd_w=8M3qy&amp;pf_rd_p=ef4dc990-a9ca-4945-ae0b-f8d549198ed6&amp;pf_rd_r=3TGSZZ1H5HYKMT0G80Q8&amp;pd_rd_r=f1e3c156-9e78-11e9-801d-cdc96cae2e7b&amp;pd_rd_wg=DXbV0&amp;pd_rd_i=3319475770&amp;psc=1&amp;refRID=3TGSZZ1H5HYKMT0G80Q8">Outlier Analysis</a>.</p></li>
<li><p>Using functional programming, extract <em>S</em> subsamples from the training data. Within each subsample, the entire positive class is retained and the negative class is down-sampled to match the size of the positive class.</p></li>
<li><p>Fit <em>S</em> models, one to each subsample.</p></li>
<li><p>Apply each of the <em>S</em> models to the testing dat to generate <em>S sets</em> of predictions.</p></li>
<li><p>Combine the <em>S sets</em> of predictions into a single vector of predictions using majority vote.</p></li>
</ol>
</div>
<div id="r-packages" class="section level1">
<h1>R packages</h1>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(tidyverse) <span class="co"># for data manipulation and %&gt;% operator</span>
<span class="kw">library</span>(rsample)   <span class="co"># train/test split</span>
<span class="kw">library</span>(ranger)    <span class="co"># random forest classifier</span>
<span class="kw">library</span>(DMwR)      <span class="co"># &quot;sales&quot; dataset</span></code></pre>
</div>
<div id="data" class="section level1">
<h1>Data</h1>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;sales&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;DMwR&quot;</span>)

sales &lt;-<span class="st"> </span>sales <span class="op">%&gt;%</span>
<span class="st">  </span>tidyr<span class="op">::</span><span class="kw">drop_na</span>() <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(Insp <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;ok&quot;</span>, <span class="st">&quot;fraud&quot;</span>)) <span class="op">%&gt;%</span><span class="st">  </span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="dt">Insp =</span> <span class="kw">factor</span>(Insp, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;ok&quot;</span>, <span class="st">&quot;fraud&quot;</span>))) </code></pre>
</div>
<div id="feature-engineering" class="section level1">
<h1>Feature Engineering</h1>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># square difference between two values x and y</span>
square_diff &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) (x <span class="op">-</span><span class="st"> </span>y)<span class="op">^</span><span class="dv">2</span>

<span class="co"># engineer features</span>
sales_features &lt;-<span class="st"> </span>sales <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="dt">LPPQ =</span> <span class="kw">log10</span>(Val <span class="op">/</span><span class="st"> </span>Quant)) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="dt">LPPQ_2 =</span> <span class="kw">square_diff</span>(LPPQ, <span class="kw">mean</span>(LPPQ))) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">group_by</span>(ID) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="dt">LPPQ_3 =</span> <span class="kw">square_diff</span>(LPPQ, <span class="kw">mean</span>(LPPQ))) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">group_by</span>(Prod) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="dt">LPPQ_4 =</span> <span class="kw">square_diff</span>(LPPQ, <span class="kw">mean</span>(LPPQ))) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">group_by</span>(ID, Prod) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">mutate</span>(<span class="dt">LPPQ_5 =</span> <span class="kw">square_diff</span>(LPPQ, <span class="kw">mean</span>(LPPQ))) <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(Insp, Quant, Val, LPPQ<span class="op">:</span>LPPQ_<span class="dv">5</span>)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">sales_features <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">head</span>() <span class="op">%&gt;%</span>
<span class="st">  </span>DT<span class="op">::</span><span class="kw">datatable</span>() <span class="op">%&gt;%</span>
<span class="st">  </span>DT<span class="op">::</span><span class="kw">formatRound</span>(<span class="dt">columns =</span> <span class="kw">c</span>(<span class="st">&quot;LPPQ&quot;</span>, <span class="st">&quot;LPPQ_2&quot;</span>, <span class="st">&quot;LPPQ_3&quot;</span>, <span class="st">&quot;LPPQ_4&quot;</span>, <span class="st">&quot;LPPQ_5&quot;</span>),
                  <span class="dt">digits =</span> <span class="dv">3</span>)</code></pre>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","data":[["1","2","3","4","5","6"],["ok","ok","ok","ok","ok","ok"],[51097,260,51282,46903,475,433],[310780,1925,278770,281485,2600,3395],[0.784057659706163,0.869457385873702,0.735281080737834,0.778254634911439,0.738279738345951,0.894351882263155],[0.0809262112526227,0.0396310945534957,0.111056832340524,0.084261521092977,0.10906720756589,0.0303390568883547],[0.00783182518833251,0.00529842576274517,0.0188442001843958,0.0602265104762983,4.8022261986868e-005,0.346422548374114],[0.00123932382400751,0.0145452663298013,0.000184214048575856,0.000864419187061162,0.017064962292554,0.000647153625724032],[0.0329603265227037,0.00477861419505438,0.0530502365893178,0.00083314191760153,0.000467100597859848,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>Insp<\/th>\n      <th>Quant<\/th>\n      <th>Val<\/th>\n      <th>LPPQ<\/th>\n      <th>LPPQ_2<\/th>\n      <th>LPPQ_3<\/th>\n      <th>LPPQ_4<\/th>\n      <th>LPPQ_5<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3,4,5,6,7,8]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false,"rowCallback":"function(row, data) {\nDTWidget.formatRound(this, row, data, 4, 3, 3, ',', '.');\nDTWidget.formatRound(this, row, data, 5, 3, 3, ',', '.');\nDTWidget.formatRound(this, row, data, 6, 3, 3, ',', '.');\nDTWidget.formatRound(this, row, data, 7, 3, 3, ',', '.');\nDTWidget.formatRound(this, row, data, 8, 3, 3, ',', '.');\n}"}},"evals":["options.rowCallback"],"jsHooks":[]}</script>
</div>
<div id="global-traintest-split" class="section level1">
<h1>Global Train/Test Split</h1>
<pre class="sourceCode r"><code class="sourceCode r">split_pct &lt;-<span class="st"> </span><span class="fl">0.8</span>

<span class="kw">set.seed</span>(<span class="dv">9560</span>)

split_idx &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">initial_split</span>(
  <span class="dt">data =</span> sales_features, 
  <span class="dt">prop =</span> split_pct,
  <span class="dt">strata =</span> <span class="st">&quot;Insp&quot;</span>
)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">train &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">training</span>(split_idx)
test &lt;-<span class="st"> </span>rsample<span class="op">::</span><span class="kw">testing</span>(split_idx)</code></pre>
</div>
<div id="subsampling" class="section level1">
<h1>Subsampling</h1>
<div id="give-specifications-for-the-subsampling-procedure." class="section level3">
<h3>Give specifications for the subsampling procedure.</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># determine the number of rows to which the negative class is down-sampled</span>
<span class="co"># by default, set to the number of positive cases</span>
downsample_level &lt;-<span class="st"> </span>train <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(Insp <span class="op">==</span><span class="st"> &quot;fraud&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">nrow</span>()

<span class="co"># number of subsamples N</span>
n_subsamples &lt;-<span class="st"> </span><span class="dv">10</span>

<span class="co"># sequence of integers from 1:N</span>
<span class="co"># used for iterations</span>
subsample_idx &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, n_subsamples, <span class="dv">1</span>)

subsample_idx</code></pre>
<pre><code>##  [1]  1  2  3  4  5  6  7  8  9 10</code></pre>
</div>
<div id="generate-subsamples" class="section level3">
<h3>Generate subsamples</h3>
<pre class="sourceCode r"><code class="sourceCode r">subsamples &lt;-<span class="st"> </span>purrr<span class="op">::</span><span class="kw">map</span>(subsample_idx, <span class="cf">function</span>(idx) {
  train <span class="op">%&gt;%</span>
<span class="st">    </span>dplyr<span class="op">::</span><span class="kw">group_by</span>(Insp) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">sample_n</span>(<span class="dt">size =</span> downsample_level) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ungroup</span>()
}) </code></pre>
</div>
</div>
<div id="training" class="section level1">
<h1>Training</h1>
<div id="fit-individual-model-to-each-subsample" class="section level3">
<h3>Fit individual model to each subsample</h3>
<pre class="sourceCode r"><code class="sourceCode r">models &lt;-<span class="st"> </span><span class="kw">map</span>(subsamples, <span class="cf">function</span>(idx) {
  ranger_model &lt;-<span class="st"> </span>ranger<span class="op">::</span><span class="kw">ranger</span>(
    <span class="dt">formula =</span> <span class="kw">as.factor</span>(Insp) <span class="op">~</span><span class="st"> </span>.,
    <span class="dt">data =</span> idx
  )
})</code></pre>
</div>
</div>
<div id="testing" class="section level1">
<h1>Testing</h1>
<div id="apply-individual-models-to-predict-testing-set" class="section level3">
<h3>Apply individual models to predict testing set</h3>
<pre class="sourceCode r"><code class="sourceCode r">model_votes &lt;-<span class="st"> </span><span class="kw">map</span>(models, <span class="cf">function</span>(idx) {
  <span class="kw">predict</span>(idx, <span class="dt">data =</span> test)<span class="op">$</span>predictions
})</code></pre>
</div>
<div id="combine-predictions-via-majority-vote" class="section level3">
<h3>Combine predictions via majority vote</h3>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># a function to compute the mode of a discrete vector</span>
majority_vote &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
  ux &lt;-<span class="st"> </span><span class="kw">unique</span>(x)
  ux[<span class="kw">which.max</span>(<span class="kw">tabulate</span>(<span class="kw">match</span>(x, ux)))]
}

final_votes &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(model_votes) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">apply</span>(., <span class="dv">1</span>, majority_vote)</code></pre>
</div>
<div id="evaluate-performance" class="section level3">
<h3>Evaluate performance</h3>
<pre class="sourceCode r"><code class="sourceCode r">caret<span class="op">::</span><span class="kw">confusionMatrix</span>(<span class="kw">factor</span>(final_votes, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;ok&quot;</span>, <span class="st">&quot;fraud&quot;</span>)),
                       test<span class="op">$</span>Insp,
                       <span class="dt">positive =</span> <span class="st">&quot;fraud&quot;</span>)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction   ok fraud
##      ok    2648    16
##      fraud  228   217
##                                           
##                Accuracy : 0.9215          
##                  95% CI : (0.9115, 0.9307)
##     No Information Rate : 0.9251          
##     P-Value [Acc &gt; NIR] : 0.7844          
##                                           
##                   Kappa : 0.6009          
##  Mcnemar&#39;s Test P-Value : &lt;2e-16          
##                                           
##             Sensitivity : 0.93133         
##             Specificity : 0.92072         
##          Pos Pred Value : 0.48764         
##          Neg Pred Value : 0.99399         
##              Prevalence : 0.07494         
##          Detection Rate : 0.06980         
##    Detection Prevalence : 0.14313         
##       Balanced Accuracy : 0.92603         
##                                           
##        &#39;Positive&#39; Class : fraud           
## </code></pre>
</div>
</div>
