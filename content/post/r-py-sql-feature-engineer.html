---
title: "A specific comparison of feature engineering in R and Python"
author: "Danny Morris"
date: "2018-01-09"
categories: ['Python']
output: 
  blogdown::html_page:
    toc: true
editor_options: 
  chunk_output_type: console
---


<div id="TOC">
<ul>
<li><a href="#purpose">Purpose</a></li>
<li><a href="#original-data">Original data</a></li>
<li><a href="#features-to-engineer">Features to engineer</a></li>
<li><a href="#r">R</a></li>
<li><a href="#python">Python</a></li>
</ul>
</div>

<div id="purpose" class="section level2">
<h2>Purpose</h2>
<p>Moving from raw data to data that is prime for analysis is called feature engineering and it is a fundamental aspect of data science. Experienced data scientists will agree that feature engineering is an essential skill.</p>
<p>This article demonstrates the same engineering pipeline written in R and Python. The pipeline is not particularly complicated, though it resembles something that a data scientist would do. I’ll be using a dataset of sales transactions that need to be engineered in order to classify fraudulent and legitimate sales.</p>
</div>
<div id="original-data" class="section level2">
<h2>Original data</h2>
<pre class="r"><code>library(DMwR) # install.packages(&quot;DMwR&quot;)

data(sales, &quot;DMwR&quot;)

head(sales)</code></pre>
<pre><code>##   ID Prod Quant   Val Insp
## 1 v1   p1   182  1665 unkn
## 2 v2   p1  3072  8780 unkn
## 3 v3   p1 20393 76990 unkn
## 4 v4   p1   112  1100 unkn
## 5 v3   p1  6164 20260 unkn
## 6 v5   p2   104  1155 unkn</code></pre>
<p>The raw data contains five variables:</p>
<p>ID: salesperson identifier</p>
<p>Prod: product identifier</p>
<p>Quant: quantity of items sold in sale</p>
<p>Val: total price of the sale</p>
<p>Insp: whether the sale is known to be fraudulent or not</p>
<p>Our end goal is to build a classifier to predict fraudulent sales. We won’t actually do that in this article, but the features we engineer will be related to this goal.</p>
</div>
<div id="features-to-engineer" class="section level2">
<h2>Features to engineer</h2>
<p>Let’s assume that fraudulent transactions can take many forms. For example, perhaps transactions for an extremely high price are an indication of credit card theft. Alternatively, transactions with many items sold for an extremely low price are an indication of suspicous discounts.</p>
<p>In our attempt to capture fraudulent sales and the various forms it can take, let’s engineer the following five features:</p>
<ol style="list-style-type: decimal">
<li><p>Price per quantity, log transformed (LPPQ): This is the total price divided by the toal quantity with a base 10 log transformation.</p></li>
<li><p>Squared difference between LPPQ and global mean LPPQ</p></li>
<li><p>Squared difference between LPPQ and mean LPPQ grouped by salesperson</p></li>
<li><p>Squared difference between LPPQ and mean LPPQ grouped by product</p></li>
<li><p>Squared difference between LPPQ and mean LPPQ grouped by salesperson and product</p></li>
</ol>
<p>In addition to these engineered features, we’ll perform some additonal preprocessing steps:</p>
<ul>
<li>remove rows with any missing values</li>
<li>randomly sample 500 fraudulent and 500 legitimate sales</li>
</ul>
</div>
<div id="r" class="section level2">
<h2>R</h2>
<p>The tidyverse ecosystem in R contains some outstanding packages for data manipulation. Most notably, the dplyr package is excellent for transformations and the tidyr package is excellent for reshaping. Both are included in the tidyverse and do not need to be installed or loaded separately. Our entire pipeline is completed using these two packages (actually, we also use the readr package for importing the csv).</p>
<p>The tidyverse utilizes the <code>%&gt;%</code> symbol (known as the “pipe” symbol) for chaining together steps in an analysis pipeline. Here is the full feature engineering pipeline in R.</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre class="r"><code>sales &lt;- sales %&gt;%
  drop_na() %&gt;%
  filter(Insp %in% c(&quot;fraud&quot;, &quot;ok&quot;)) %&gt;%  
  group_by(Insp) %&gt;%
  sample_n(size = 500) %&gt;%
  ungroup()

sq_diff &lt;- function(x, y) (x - y)^2

r_engineered &lt;- sales %&gt;%
  mutate(LPPQ = log10(Val / Quant)) %&gt;%
  mutate(LPPQ_2 = sq_diff(LPPQ, mean(LPPQ))) %&gt;%
  group_by(ID) %&gt;%
  mutate(LPPQ_3 = sq_diff(LPPQ, mean(LPPQ))) %&gt;%
  group_by(Prod) %&gt;%
  mutate(LPPQ_4 = sq_diff(LPPQ, mean(LPPQ))) %&gt;%
  group_by(ID, Prod) %&gt;%
  mutate(LPPQ_5 = sq_diff(LPPQ, mean(LPPQ))) %&gt;%
  ungroup()

head(r_engineered)</code></pre>
<pre><code>## # A tibble: 6 x 10
##   ID    Prod  Quant    Val Insp   LPPQ   LPPQ_2    LPPQ_3   LPPQ_4   LPPQ_5
##   &lt;fct&gt; &lt;fct&gt; &lt;int&gt;  &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;
## 1 v1171 p1914   100   1025 ok    1.01   4.14e-3   1.99e-6  8.92e-3  1.99e-6
## 2 v1109 p1669   269   9710 ok    1.56   3.73e-1   6.67e-2  5.35e-5  0.     
## 3 v3796 p3995   169   1475 ok    0.941  3.01e-5   0.       1.26e-1  0.     
## 4 v1179 p1818  1188 103885 ok    1.94   9.91e-1   0.       6.91e-3  0.     
## 5 v896  p3072   372   3980 ok    1.03   6.88e-3   0.       2.59e-3  0.     
## 6 v654  p2278 10341 220565 ok    1.33   1.46e-1   0.       7.06e-3  0.</code></pre>
</div>
<div id="python" class="section level2">
<h2>Python</h2>
<p>We’ll use a combination of pandas, numpy, and scikit learn to engineer the features in Python.</p>
<pre class="r"><code>reticulate::use_condaenv(&quot;r-reticulate&quot;, required = TRUE)</code></pre>
<pre class="python"><code>import pandas as pd
import numpy as np
from sklearn.utils import resample </code></pre>
<pre class="python"><code>sales = pd.read_csv(&#39;sales.csv&#39;)
sales = sales.dropna()
sales_ok = sales[sales.Insp == &#39;ok&#39;]
sales_fraud = sales[sales.Insp == &#39;fraud&#39;]
resample_ok = resample(sales_ok, replace = False, n_samples = 500)
resample_fraud = resample(sales_fraud, replace = False, n_samples = 500) 
sales = pd.concat([resample_ok, resample_fraud])
sales[&#39;LPPQ&#39;] = np.log10(sales.Val/sales.Quant)
sales[&#39;LPPQ_2&#39;] = sales.LPPQ - np.mean(sales.LPPQ)
def get_group_mean(group_vars, col_name):
  group_df = sales.groupby(group_vars, as_index = False)[&#39;LPPQ&#39;]
  group_mean = group_df.mean()
  group_mean = group_mean.rename(index = str, columns = {&quot;LPPQ&quot;: col_name})
  return group_mean
LPPQ_3 = get_group_mean(group_vars = [&#39;ID&#39;], col_name = &#39;LPPQ_3&#39;)
LPPQ_4 = get_group_mean(group_vars = [&#39;Prod&#39;], col_name = &#39;LPPQ_4&#39;)
LPPQ_5 = get_group_mean(group_vars = [&#39;Prod&#39;, &#39;ID&#39;], col_name = &#39;LPPQ_5&#39;)
sales = sales.merge(LPPQ_3, how = &#39;inner&#39;, on = &#39;ID&#39;)
sales = sales.merge(LPPQ_4, how = &#39;inner&#39;, on = &#39;Prod&#39;) 
sales = sales.merge(LPPQ_5, how = &#39;inner&#39;, on = [&#39;ID&#39;, &#39;Prod&#39;])
def sq_diff(x):
  return (x - sales.LPPQ)**2
  
sales[[&#39;LPPQ_2&#39;,&#39;LPPQ_3&#39;, &#39;LPPQ_4&#39;, &#39;LPPQ_5&#39;]] = sales[[&#39;LPPQ_2&#39;,&#39;LPPQ_3&#39;, &#39;LPPQ_4&#39;, &#39;LPPQ_5&#39;]].apply(sq_diff)
sales.head()</code></pre>
</div>
